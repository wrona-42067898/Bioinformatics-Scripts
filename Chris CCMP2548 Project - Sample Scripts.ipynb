{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts - Symbiodinium CCMP2548 Variant Analysis\n",
    "\n",
    "Outline of the scripts I've run so far. No results are displayed in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "700bp Mar 2017  \n",
    "700bp April 2017  \n",
    "700bp December 2016  \n",
    "250bp July 2016  \n",
    "400bp April 2018  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about PBS headers for working on Raijin\n",
    "\n",
    "**Mandatory**  \n",
    "\\#PBS -P d85  \n",
    "\\#PBS -V -l ncpus=xx, mem=xxGB, walltime=xxx:xx:xx\"  \n",
    "\\#PBS -l wd  \n",
    "\\#PBS -N $jobname  \n",
    "  \n",
    "**Optional**  \n",
    "Receive e-mail on (a)bort, (b)egins, (e)nd  \n",
    "\\#PBS -M christopher.wrona@uqconnect.edu.au  \n",
    "\\#PBS -m abe  \n",
    "  \n",
    "Run job in express queue (Maximum walltime 24 hrs)  \n",
    "\\#PBS -q express  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "PATH = \"C:/Users/chris/OneDrive/Symbiodinium/script_summaries/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read preparation / trimming\n",
    "### FastQC of raw reads\n",
    "  \n",
    "Simple analysis of raw reads with FASTQC to determine trimming parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $PBS_O_WORKDIR \n",
    "\n",
    "export INDIR=/home/c.wrona/Reads\n",
    "export OUTDIR=/home/c.wrona/Chris/fastqc_output\n",
    "\n",
    "for file in $INDIR/*;\n",
    "        do\n",
    "                fastqc -o $OUTDIR $file\n",
    "        done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming of raw reads\n",
    "\n",
    "Reads were trimmed stringently (>Q30). FastQC revealed subsantial nucleotide bias in the trailing 5 bases of 700bp libraries, which was taken into consideration with subsequent trimming parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -V -l nodes=1:ppn=16,mem=30GB,walltime=100:00:00\n",
    "#PBS -k oe\n",
    "#PBS -N Trimmomatic_Chris_PE\n",
    "\n",
    "cd $PBS_O_WORKDIR #dir where you submitted job \n",
    "\n",
    "module load trimmomatic/0.36 #load trimmomatic\n",
    "\n",
    "trim_250_jul() {\n",
    "R1=$1\n",
    "R1_prefix=$(echo $R1 | cut -d'/' -f5 | cut -d'.' -f1)\n",
    "R2=$(echo $R1 | sed 's/R1/R2/g') \n",
    "R2_prefix=$(echo $R1 | cut -d'/' -f5 | cut -d'.' -f1 | sed 's/R1/R2/g')\n",
    "trimlog_prefix=$(echo $R1 | cut -d'/' -f5  | cut -d'.' -f1 | cut -d'_' -f1-3)\n",
    "adapter_file=$2\n",
    "trimmomatic PE -threads 16 -phred33 -trimlog ${trimlog_prefix}_trimlog $R1 $R2 ${R1_prefix}_trimmed.fastq.gz ${R1_prefix}_Fsingle.fastq.gz ${R2_prefix}_trimmed.fastq.gz ${R2_prefix}_Rsingle.fastq.gz \\\n",
    "ILLUMINACLIP:${adapter_file}:2:30:10 HEADCROP:10 LEADING:30 TRAILING:30 SLIDINGWINDOW:4:25 MINLEN:100 AVGQUAL:30\n",
    "}\n",
    "\n",
    "trim_700_all() {\n",
    "R1=$1\n",
    "R1_prefix=$(echo $R1 | cut -d'/' -f5 | cut -d'.' -f1)\n",
    "R2=$(echo $R1 | sed 's/R1/R2/g') \n",
    "R2_prefix=$(echo $R1 | cut -d'/' -f5 | cut -d'.' -f1 | sed 's/R1/R2/g')\n",
    "trimlog_prefix=$(echo $R1 | cut -d'/' -f5  | cut -d'.' -f1 | cut -d'_' -f1-3)\n",
    "adapter_file=$2\n",
    "trimmomatic PE -threads 16 -phred33 -trimlog ${trimlog_prefix}_trimlog $R1 $R2 ${R1_prefix}_trimmed.fastq.gz ${R1_prefix}_Fsingle.fastq.gz ${R2_prefix}_trimmed.fastq.gz ${R2_prefix}_Rsingle.fastq.gz \\\n",
    "ILLUMINACLIP:${adapter_file}:2:30:10 CROP:145 HEADCROP:10 LEADING:30 TRAILING:30 SLIDINGWINDOW:4:25 MINLEN:100 AVGQUAL:30\n",
    "}\n",
    "\n",
    "#arg 1: path to the first read of a pair (fastq.gz format)\n",
    "#arg 2: path to the adapter file\n",
    "trim_250_jul /home/c.wrona/Reads/CCMP2548_PE250bp_Jul2016_R1.fastq.gz /home/c.wrona/TrimmomaticAdapters/TruSeq3-PE-AD12.fa\n",
    "trim_700_all /home/c.wrona/Reads/CCMP2548_PE700bp_Apr2017_R1.fastq.gz /home/c.wrona/TrimmomaticAdapters/TruSeq3-PE-AD19.fa\n",
    "trim_700_all /home/c.wrona/Reads/CCMP2548_PE700bp_Dec2016_R1.fastq.gz /home/c.wrona/TrimmomaticAdapters/TruSeq3-PE-AD19.fa \n",
    "trim_700_all /home/c.wrona/Reads/CCMP2548_PE700bp_Mar2017_R1.fastq.gz /home/c.wrona/TrimmomaticAdapters/TruSeq3-PE-AD19.fa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIB_SIZE</th>\n",
       "      <th>LIB_DATE</th>\n",
       "      <th>ADAPTER_FILE</th>\n",
       "      <th>ILLUMINACLIP</th>\n",
       "      <th>HEADCROP</th>\n",
       "      <th>CROP</th>\n",
       "      <th>LEADING</th>\n",
       "      <th>TRAILING</th>\n",
       "      <th>SLIDINGWINDOW</th>\n",
       "      <th>MINLEN</th>\n",
       "      <th>AVGQUAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250bp</td>\n",
       "      <td>Jul-16</td>\n",
       "      <td>TruSeq3-PE-AD12.fa</td>\n",
       "      <td>2:30:10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>4:25</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700bp</td>\n",
       "      <td>Apr-17</td>\n",
       "      <td>TruSeq3-PE-AD19.fa</td>\n",
       "      <td>2:30:10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>4:25</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700bp</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>TruSeq3-PE-AD19.fa</td>\n",
       "      <td>2:30:10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>4:25</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700bp</td>\n",
       "      <td>Mar-17</td>\n",
       "      <td>TruSeq3-PE-AD19.fa</td>\n",
       "      <td>2:30:10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>4:25</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LIB_SIZE LIB_DATE        ADAPTER_FILE ILLUMINACLIP  HEADCROP  CROP  LEADING  \\\n",
       "0    250bp   Jul-16  TruSeq3-PE-AD12.fa      2:30:10        10     0       30   \n",
       "1    700bp   Apr-17  TruSeq3-PE-AD19.fa      2:30:10        10     5       30   \n",
       "2    700bp   Dec-16  TruSeq3-PE-AD19.fa      2:30:10        10     5       30   \n",
       "3    700bp   Mar-17  TruSeq3-PE-AD19.fa      2:30:10        10     5       30   \n",
       "\n",
       "   TRAILING SLIDINGWINDOW  MINLEN  AVGQUAL  \n",
       "0        30          4:25     100       30  \n",
       "1        30          4:25     100       30  \n",
       "2        30          4:25     100       30  \n",
       "3        30          4:25     100       30  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_parameters = pd.read_csv(PATH + 'trimmomatic_parameters.csv', sep=',')\n",
    "trim_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above:** Trimmomatic parameters used for paired-end trimming of raw reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-mer counting with Jellyfish\n",
    "Obtain an estimate of the coverage for each library and genome size. This was done to inform whether I will likely have enough coverage for variant calling (100X) with just paired end reads in which both survived trimming.\n",
    "\n",
    "**Tools:** Jellyfish, R (script is written in R)\n",
    "\n",
    "Guide for manually checking a single library and single k-mer size.  \n",
    "http://koke.asrc.kanazawa-u.ac.jp/HOWTO/kmer-genomesize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Directory to all my .histo files\n",
    "files <- list.files(path=\"C:\\\\Users\\\\chris\\\\OneDrive\\\\Symbiodinium\\\\jellyfish\\\\jellyfish_histograms\\\\\", full.names=T, recursive=FALSE)\n",
    "\n",
    "##Empty dataframe with appropriate column names\n",
    "jellyfish_dataframe <- data.frame(Name=character(),\n",
    "                                  Peak_Size=integer(), \n",
    "                                  Total_Genome_Size=integer(), \n",
    "                                  stringsAsFactors=FALSE) \n",
    "\n",
    "\n",
    "##Loop through each histogram file\n",
    "for (file in files){\n",
    "  data <- read.table(file) ##Read file into a table\n",
    "  suffix <- unlist(strsplit((substring(file, 69)), split='.',fixed=TRUE))[1] ##Save a portion of file name\n",
    "  \n",
    "  ##Find the index after the initial skewed values\n",
    "  for (count in 2:10){\n",
    "    if (data[count,'V2'] < data[count-1,'V2'])\n",
    "      start_index <- count \n",
    "  }\n",
    "  \n",
    "  ##Calculations\n",
    "  subset <- data[start_index:nrow(data),] ##Subset the dataframe to exclude erroneous starting values\n",
    "  peak_pos <- which.max(subset$V2) + (start_index-1)\n",
    "  tot_genome_size <- sum(as.numeric(subset[,1]*subset[,2]))/peak_pos\n",
    "  \n",
    "  \n",
    "  ##Append results to the empty dataframe initialised earlier\n",
    "  temp_df <- data.frame(Name=suffix, Peak_Size=peak_pos, Total_Genome_Size=tot_genome_size)\n",
    "  jellyfish_dataframe <- rbind(jellyfish_dataframe, temp_df)\n",
    "}\n",
    "\n",
    "##Write out the (not averaged) values to a txt file (commented out)\n",
    "#write.table(jellyfish_dataframe, file = \"jellyfish_output.txt\", append = FALSE, quote = TRUE, sep = \" \")\n",
    "\n",
    "\n",
    "##Create vectors of averaged values for each library\n",
    "avg_peaks <- round(colMeans(matrix(jellyfish_dataframe$Peak_Size, nrow=6)), digits=2)\n",
    "avg_sizes <- colMeans(matrix(jellyfish_dataframe$Total_Genome_Size, nrow=6))\n",
    "avg_names <- matrix(jellyfish_dataframe$Name[seq(1, nrow(jellyfish_dataframe) , 6)])\n",
    "\n",
    "avg_peaks\n",
    "avg_sizes\n",
    "avg_names\n",
    "\n",
    "##clean up avg_names vector (remove the '_xxmer' suffix)\n",
    "strip_ends <- function(txt){\n",
    "    return (substr(txt, 1, nchar(txt)-6))\n",
    "}\n",
    "\n",
    "avg_names <- apply(avg_names, 1, strip_ends) \n",
    "\n",
    "##Join vectors into a final dataframe of average values!\n",
    "averaged_dataframe <- data.frame(Name=avg_names, \n",
    "                                 Avg_Peak_size=avg_peaks, \n",
    "                                 Avg_Genome_Size=avg_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split .fastq.gz ##\n",
    "\n",
    "Split 400bp library files prior to read mapping to allow samples run on lane 6 and lane 8 to be differentiated in readgroup information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=8,mem=20GB,walltime=150:00:00\n",
    "#PBS -k oe\n",
    "#PBS -l wd\n",
    "#PBS -N split_400bp_N\n",
    "\n",
    "cd /home/564/cw7616/Chris/PE_400bp_trimmed/paired\n",
    "\n",
    "zcat CCMP2548_PE400bp_Apr2018_P1.fastq.gz | grep --no-group-separator -A 3 \"HNW23BBXX:8\" > CCMP2548_L8_PE400bp_Apr2018_P1.fastq\n",
    "\n",
    "gzip CCMP2548_L8_PE400bp_Apr2018_P1.fastq\n",
    "\n",
    "zcat CCMP2548_PE400bp_Apr2018_P1.fastq.gz | grep --no-group-separator -A 3 \"HNW23BBXX:6\" > CCMP2548_L6_PE400bp_Apr2018_P1.fastq\n",
    "\n",
    "gzip CCMP2548_L6_PE400bp_Apr2018_P1.fastq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually check that the lengths of split files (L6 and L8) add up to the original file to ensure all reads are accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcat CCMP2548_PE400bp_Apr2018_P1.fastq.gz | wc -l \n",
    "zcat CCMP2548_L6_PE400bp_Apr2018_P1.fastq.gz | wc -l\n",
    "zcat CCMP2548_L8_PE400bp_Apr2018_P1.fastq.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Mapping\n",
    "\n",
    "**tools:** bwa, samtools  \n",
    "  \n",
    "**input:** trimmed fastq.gz files for each pair  \n",
    "**output:** bam files for each pair  \n",
    "  \n",
    "**bwa parameters**  \n",
    "-M\tMark shorter split reads (chimeras) as secondary for Picard compatibility.  \n",
    "-R  Complete read group header line.  \n",
    "\n",
    "**samtools**  \n",
    "output is piped to *samtools view -bS*  \n",
    "-b  Output in the BAM format.  \n",
    "-S  Ignored for compatibility with previous samtools versions.  \n",
    "\n",
    "  \n",
    "**bwa manual page**\n",
    "http://bio-bwa.sourceforge.net/bwa.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=20GB,walltime=200:00:00\n",
    "#PBS -k oe\n",
    "#PBS -l wd\n",
    "#PBS -N readgroup_fix_bwa\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/all_PE\n",
    "cd $INDIR\n",
    "\n",
    "module load samtools/1.4\n",
    "\n",
    "bwa_all()\n",
    "{\n",
    "R1=$1 \n",
    "R1_prefix=$(echo $R1 | cut -d'/' -f7)\n",
    "R2=$(echo $R1 | sed 's/R1/R2/g')\n",
    "R2_prefix=$(echo $R2 | cut -d'/' -f7)\n",
    "\n",
    "OUTFILE=$(echo $R1_prefix | cut -d'_' -f1-3)\n",
    "\n",
    "bwa mem -M -R \"@RG\\tID:${2}\\tPL:\"ILLUMINA\"\\tSM:${3}\\tLB:${4}\" /\n",
    "    sspace_MPclean.final.scaffolds.fasta /\n",
    "    ${R1_prefix} ${R2_prefix} | samtools view -bS - > ${OUTFILE}.bam\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#$1 = path to read\n",
    "#$2 = flowcell ID and number\n",
    "#$3 = Sample (all are CCMP2548)\n",
    "#$4 = Library information\n",
    "#Note that these readgroups were lated adjusted using Picard's AddOrReplaceReadgroups\n",
    "bwa_all /home/564/cw7616/Chris/all_PE/CCMP2548_PE250bp_Jul2016_R1_trimmed.fastq.gz \"HM75TBCXX:2\" \"CCMP2548\" \"PE250JUL2016\"\n",
    "\n",
    "bwa_all /home/564/cw7616/Chris/all_PE/CCMP2548_PE700bp_Apr2017_R1_trimmed.fastq.gz \"HHLL2BBXX:8\" \"CCMP2548\" \"PE700APR2017\"\n",
    "\n",
    "bwa_all /home/564/cw7616/Chris/all_PE/CCMP2548_PE700bp_Dec2016_R1_trimmed.fastq.gz \"HGLFMBBXX:8\" \"CCMP2548\" \"PE700DEC2016\"\n",
    "\n",
    "bwa_all /home/564/cw7616/Chris/all_PE/CCMP2548_PE700bp_Mar2017_R1_trimmed.fastq.gz \"HGVVMBBXX:8\" \"CCMP2548\" \"PE700MAR2017\"\n",
    "\n",
    "bwa_all /home/564/cw7616/Chris/all_PE/CCMP2548_L6_PE400bp_Apr2018_sorted.bam \"HNW23BBXX:6\" \"CCMP2548\" \"PE400APR\"\n",
    "\n",
    "bwa_all /home/564/cw7616/Chris/all_PE/CCMP2548_L8_PE400bp_Apr2018_sorted.bam \"HNW23BBXX:8\" \"CCMP2548\" \"PE400APR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by Coordinate\n",
    "**tools:** picard  \n",
    "  \n",
    "BAM files are sorted by coordinate. For a coordinate sorted SAM/BAM file, read alignments are sorted first by the reference sequence name (RNAME) field using the reference sequence dictionary tag labeled SQ. Alignments within these subgroups are secondarily sorted using the left-most mapping position of the read (POS). Subsequent to this sorting scheme, alignments are listed arbitrarily.  \n",
    "  \n",
    "**input:** unsorted bam files  \n",
    "**output:** sorted bam files  \n",
    "  \n",
    "**reference**  \n",
    "https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.1.0/picard_sam_SortSam.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=20GB,walltime=200:00:00\n",
    "#PBS -k oe\n",
    "#PBS -l wd\n",
    "#PBS -N picard_sort\n",
    "\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/bams_all\n",
    "export PICARD=/home/564/cw7616/programs/picard.jar\n",
    "cd $INDIR\n",
    "\n",
    "\n",
    "pic_sort()\n",
    "{\n",
    "input_name=$(echo $1 | cut -d \"/\"  -f7 )\n",
    "output_name=$(echo $input_name | cut -d '.' -f1)_sorted.bam\n",
    "\n",
    "\n",
    "java -jar ${PICARD} SortSam INPUT=$input_name OUTPUT=$output_name SORT_ORDER=coordinate\n",
    "\n",
    "}\n",
    "\n",
    "for filename in ${INDIR}/*; do\n",
    "        pic_sort $filename\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Readgroup Information\n",
    "**tools:** picard  \n",
    "  \n",
    "**input:** sorted bam  \n",
    "**output:** sorted bam with adjusted readgroups  \n",
    "  \n",
    "**reference:**  \n",
    "https://broadinstitute.github.io/picard/command-line-overview.html#AddOrReplaceReadGroups\n",
    "  \n",
    "I adjusted readgroup information to reflect that each 700bp run was from the same library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=20GB,walltime=24:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N fix_readgroups\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load samtools/1.4\n",
    "\n",
    "INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "PICARD=/home/564/cw7616/programs/picard.jar\n",
    "cd $INDIR\n",
    "\n",
    "\n",
    "fix_readgroups()\n",
    "{\n",
    "input_file=$1\n",
    "RG_ID=$2\n",
    "RG_LB=$3\n",
    "RG_PL=$4\n",
    "RG_PU=$5\n",
    "RG_SM=$6\n",
    "RG_DT=$7\n",
    "output_file=$(echo $input_file | sed 's/.bam/_RGFIX.bam/')\n",
    "\n",
    "echo $input_file\n",
    "echo \"outfile is $output_file\"\n",
    "\n",
    "java -jar $PICARD AddOrReplaceReadGroups I=$input_file O=$output_file RGID=$RG_ID RGLB=$RG_LB RGPL=$RG_PL RGPU=$RG_PU RGSM=$RG_SM RGDT=$RG_DT\n",
    "\n",
    "}\n",
    "\n",
    "fix_readgroups CCMP2548_PE700bp_Apr2017_sorted.bam \"HHLL2BBXX:8\" \"PE700DECMARAPR\" \"ILLUMINA\" \"HHLL2BBXX:8\" \"CCMP2548\" \"2017-04-01\"\n",
    "\n",
    "fix_readgroups CCMP2548_PE700bp_Dec2016_sorted.bam \"HGLFMBBXX:8\" \"PE700DECMARAPR\" \"ILLUMINA\" \"HGLFMBBXX:8\" \"CCMP2548\" \"2016-12-01\"\n",
    "\n",
    "fix_readgroups CCMP2548_PE700bp_Mar2017_sorted.bam \"HGVVMBBXX:8\" \"PE700DECMARAPR\" \"ILLUMINA\" \"HGVVMBBXX:8\" \"CCMP2548\" \"2017-03-01\"\n",
    "\n",
    "fix_readgroups CCMP2548_PE250bp_Jul2016_sorted.bam \"HM75TBCXX:2\" \"PE250JUL\" \"ILLUMINA\" \"HM75TBCXX:2\" \"CCMP2548\" \"2016-07-01\"\n",
    "\n",
    "fix_readgroups CCMP2548_L6_PE400bp_Apr2018_sorted.bam \"HNW23BBXX:6\" \"PE400APR\" \"ILLUMINA\" \"HNW23BBXX:6\" \"CCMP2548\" \"2018-04-01\"\n",
    "\n",
    "fix_readgroups CCMP2548_L8_PE400bp_Apr2018_sorted.bam \"HNW23BBXX:8\" \"PE400APR\" \"ILLUMINA\" \"HNW23BBXX:8\" \"CCMP2548\" \"2018-04-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Alignment Metrics and Remove Duplicates\n",
    "**tools:** samtools, picard, R\n",
    "  \n",
    "**input:** sorted bam  \n",
    "**output metrics:** alignment metrics, insert metrics, insert size histogram, depth metrics    \n",
    "**output remove duplicates:** bam file with duplicates removed, duplicate metrics  \n",
    " \n",
    "**notes:**  \n",
    "It was important to parse -Xmx80g to java when running Picard's MarkDuplicates to prevent it throwing an error regarding insufficient memory. Note that simply supplying more memory in the PBS header is not sufficient without the java arguement. I also had to point to a temp folder in my directory to store temp files, as the default directory had very limited capacity.  \n",
    "  \n",
    "**references:**  \n",
    "CollectAlignmentSummaryMetrics: https://software.broadinstitute.org/gatk/documentation/tooldocs/current/picard_analysis_CollectAlignmentSummaryMetrics.php  \n",
    "CollectInsertSizeMetrics:  \n",
    "https://broadinstitute.github.io/picard/command-line-overview.html  \n",
    "MarkDuplicates:  \n",
    "https://broadinstitute.github.io/picard/command-line-overview.html#MarkDuplicates  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=80GB,walltime=24:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N 3_4_metrics_dedupe\n",
    "\n",
    "export PICARD=/home/564/cw7616/programs/picard.jar\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/sorted_bams\n",
    "cd $INDIR\n",
    "\n",
    "module load samtools/1.4\n",
    "module load java/jdk1.8.0_60\n",
    "module load R/3.4.3\n",
    "\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "\n",
    "###COLLECT ALIGNMENT AND INSERT SIZE METRICS###\n",
    "collect_metrics()\n",
    "{\n",
    "input_name=$(echo $1 | cut -d \"/\"  -f8 )\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/_sorted_RGFIX//')\n",
    "\n",
    "java -jar $PICARD CollectAlignmentSummaryMetrics R=$2 I=$input_name O=alignment_metrics_${output_name}.txt\n",
    "\n",
    "java -jar $PICARD CollectInsertSizeMetrics INPUT=${input_name} OUTPUT=insert_metrics_${output_name}.txt HISTOGRAM_FILE=ins_size_histo_${output_name}.pdf\n",
    "\n",
    "samtools depth -a ${input_name} > depth_out_${output_name}.txt\n",
    "}\n",
    "\n",
    "\n",
    "###REMOVE DUPLICATES###\n",
    "pic_dedup()\n",
    "{\n",
    "input_name=$(echo $1 | cut -d \"/\"  -f8 )\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/_sorted_RGFIX//')\n",
    "\n",
    "\n",
    "java -Xmx80g -Djava.io.tmpdir=`pwd`/tmp  -jar ${PICARD} MarkDuplicates INPUT=${input_name} OUTPUT=${output_name}_dedup.bam METRICS_FILE=${output_name}_dedup_metrics.txt TMP_DIR=`pwd`/tmp\n",
    "}\n",
    "\n",
    "for filename in ${INDIR}/*RGFIX.bam; do\n",
    "        collect_metrics $filename $REF\n",
    "\tpic_dedup $filename\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge bams\n",
    "**tools:** picard\n",
    "  \n",
    "**input:** bam file with duplicates removed  \n",
    "**output files:** single bam file with data from all libraries\n",
    "   \n",
    "I collected metrics on each final individually above as I thought maybe having that individual information would be useful. I then wanted to merge all my BAM's into a single file so variants could all be called together (and all further downstream processing).  \n",
    "  \n",
    "**references:**   \n",
    "https://broadinstitute.github.io/picard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=40GB,walltime=24:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N merge_bams\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/4_5_dedup\n",
    "export PICARD=/home/564/cw7616/programs/picard.jar\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "\n",
    "F1=CCMP2548_L6_PE400bp_Apr2018_dedup.bam\n",
    "F2=CCMP2548_L8_PE400bp_Apr2018_dedup.bam\n",
    "F3=CCMP2548_PE250bp_Jul2016_dedup.bam\n",
    "F4=CCMP2548_PE700bp_Apr2017_dedup.bam\n",
    "F5=CCMP2548_PE700bp_Dec2016_dedup.bam\n",
    "F6=CCMP2548_PE700bp_Mar2017_dedup.bam\n",
    "\n",
    "java -jar $PICARD MergeSamFiles \\\n",
    "\tI=$F1 \\\n",
    "\tI=$F2 \\\n",
    "\tI=$F3 \\\n",
    "\tI=$F4 \\\n",
    "\tI=$F5 \\\n",
    "\tI=$F6 \\\n",
    "\tO=CCMP2548_all_dedup.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index BAMs, Realignment Targets and Indel Realignment\n",
    "**tools:** picard, gatk\n",
    "\n",
    "### Index BAMs  \n",
    "**input:** Merged bam file with duplicates removed.  \n",
    "**output:** BAM index \".bai\" file.  \n",
    "  \n",
    "**notes:**\n",
    "This tool creates an index file for the input BAM that allows fast look-up of data in a BAM file, like an index on a database. Note that the input BAM file must be sorted in coordinate order.  \n",
    "  \n",
    "**references:**  \n",
    "https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.1.1/picard_sam_BuildBamIndex.php\n",
    "  \n",
    "  \n",
    "### Realignment 1: Create Realignment Targets [NOT NEEDED]\n",
    "**input:** Merged bam file with duplicates removed, reference genome  \n",
    "**output:** realignment_targets.list file  \n",
    "  \n",
    "**notes:**\n",
    "The local realignment process is designed to consume one or more BAM files and to locally realign reads such that the number of mismatching bases is minimized across all the reads. This process consists of 1) determining (small) suspicious intervals which are likely in need of realignment (RealignerTargetCreator) and 2) running the realigner over those intervals (IndelRealigner).    \n",
    "  \n",
    "**references:**   \n",
    "https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_tools_walkers_indels_RealignerTargetCreator.php\n",
    "  \n",
    "  \n",
    "### Realignment 2: Indel Realignment [NOT NEEDED]\n",
    "**input:** Merged bam file with duplicates removed, reference genome, list of realignment targets  \n",
    "**output:** BAM file with realigned reads.    \n",
    "  \n",
    "**references:**  \n",
    "https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_tools_walkers_indels_IndelRealigner.php\n",
    "  \n",
    "  \n",
    "**additional notes:**  \n",
    "Indel realignment is not actually deemed necessary in GATK version 4.xx best practices as it is now built into HaplotypeCaller, so this step was largely redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=50GB,walltime=24:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N 5_6_7_index_and_realign\n",
    "\n",
    "export PICARD=/home/564/cw7616/programs/picard.jar\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/4_5_dedup\n",
    "export GATK=/home/564/cw7616/programs/GenomeAnalysisTK.jar\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load python3/3.6.2\n",
    "module load gatk/3.6\n",
    "\n",
    "###Step 5###\n",
    "bam_index()\n",
    "{\n",
    "input_name=$1\n",
    "\n",
    "java -Xmx40g -Djava.io.tmpdir=`pwd`/tmp  -jar ${PICARD}  BuildBamIndex INPUT=${input_name} TMP_DIR=`pwd`/tmp\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "###Step 6###\n",
    "gatk_realignment_targets()\n",
    "{\n",
    "input_name=$1\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/_dedup/_realignment_targets.list/')\n",
    "\n",
    "java -Xmx40g -Djava.io.tmpdir=`pwd`/tmp -jar $GATK -T RealignerTargetCreator -R $REF -I $input_name -o ${output_name}\n",
    "}\n",
    "\n",
    "###Step 7###\n",
    "gatk_realignment()\n",
    "{\n",
    "input_name=$1\n",
    "target_name=$(echo $input_name | cut -d '.' -f1 | sed 's/_dedup/_realignment_targets.list/')\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/_dedup/_realigned_reads.bam/')\n",
    "\n",
    "java -Xmx40g -Djava.io.tmpdir=`pwd`/tmp -jar $GATK -T IndelRealigner -R $REF -I $input_name -targetIntervals ${target_name} -o ${output_name}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "bam_index CCMP2548_all_dedup.bam\n",
    "\n",
    "gatk_realignment_targets CCMP2548_all_dedup.bam\n",
    "\n",
    "gatk_realignment CCMP2548_all_dedup.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Round of Calling Variants\n",
    "  \n",
    "Reasoning: Base Quality Score Recalibration relies upon calculating 'empirical error' in base calls to find patterns in how covariates effect it. To do this, it makes the broad assumption that **any mismatch** against a reference is an error.  \n",
    "In humans you would parse in a list of known variable sites to mask them from this, but since we have no known variant resource we bootstrap the variants in this way.\n",
    "  \n",
    "**tools:** GATK HaplotypeCaller  \n",
    "  \n",
    "**input:** Merged bam of realigned reads.  \n",
    "**output:** \"raw variant\" vcf file.  \n",
    "  \n",
    "**notes:**  \n",
    "Calls germline SNPs and indels via local re-assembly of haplotypes.\n",
    "    - Identifies active regions (variation, coverage)\n",
    "    - Assembles plausible haplotypes (graphs)\n",
    "    - Likelihoods of each read against each possible haplotype (HMM)\n",
    "    - Variant/genotype inference\n",
    "  \n",
    "**references:**  \n",
    "https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.4.0/org_broadinstitute_hellbender_tools_walkers_haplotypecaller_HaplotypeCaller.php\n",
    "  \n",
    "  \n",
    "\n",
    "**additional notes:**  \n",
    "Computationally itensive (walltime used: 42:29:11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=32GB,walltime=200:00:00\n",
    "#PBS -l wd\n",
    "#PBS -M christopher.wrona@uqconnect.edu.au\n",
    "#PBS -m abe\n",
    "#PBS -N 8_call_variants_GATK4\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/4_5_dedup\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load python3/3.6.2\n",
    "\n",
    "\n",
    "call_variants()\n",
    "{\n",
    "input_name=$1\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/realigned_reads/raw_variants.vcf/')\n",
    "\n",
    "gatk HaplotypeCaller -R $REF -I $input_name -O $output_name\n",
    "}\n",
    "\n",
    "\n",
    "call_variants CCMP2548_all_realigned_reads.bam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract SNPs and Indels\n",
    "**tools:** GATK SelectVariants  \n",
    "  \n",
    "**input:**   raw variant vcf file  \n",
    "**output:**  raw SNP vcf file, raw INDEL vcf file  \n",
    "  \n",
    "**notes:**  \n",
    "This step separates SNPs and INDELs into individual files so they can be processed independently.  \n",
    "  \n",
    "**references:**  \n",
    "https://software.broadinstitute.org/gatk/documentation/tooldocs/4.beta.6/org_broadinstitute_hellbender_tools_walkers_variantutils_SelectVariants.php\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=32GB,walltime=24:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N 9_extract_snps+indels\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load python3/3.6.2\n",
    "\n",
    "gatk_extract()\n",
    "{\n",
    "input_name=$1\n",
    "snp_out=$(echo $input_name | cut -d '.' -f1 | sed 's/raw_variants/raw_snps.vcf/')\n",
    "indel_out=$(echo $input_name | cut -d '.' -f1 | sed 's/raw_variants/raw_indels.vcf/')\n",
    "\n",
    "echo $snp_out\n",
    "echo $indel_out\n",
    "\n",
    "gatk SelectVariants -R $REF -V $input_name --select-type SNP -O $snp_out\n",
    "\n",
    "gatk SelectVariants -R $REF -V $input_name --select-type INDEL -O $indel_out\n",
    "\n",
    "}\n",
    "\n",
    "gatk_extract CCMP2548_all_raw_variants.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter SNPs and Indels\n",
    "**tools:** GATK VariantFiltration\n",
    "  \n",
    "**input:**   raw SNP vcf file, raw INDEL vcf file\n",
    "**output:**  filtered SNP vcf file, filtered INDEL vcf file  \n",
    "  \n",
    "**notes:**  \n",
    "Apply filtering parameters to SNPs and INDELs based on criteria recommended in GATK best practices. These criteria are as follows:  \n",
    "  \n",
    "    SNP criteria  \n",
    "    - QD < 2.0  \n",
    "    - FS > 60.0   \n",
    "    - MQ < 40.0  \n",
    "    - MQRankSum < -12.5  \n",
    "    - ReadPosRankSum < -8.0  \n",
    "    - SOR > 4.0  \n",
    "    INDEL criteria  \n",
    "    - QD < 2.0  \n",
    "    - FS > 200.0  \n",
    "    - ReadPosRankSum < -20.0  \n",
    "    - SOR > 10.0  \n",
    "  \n",
    "**references:**  \n",
    "good articles explaining filtering criteria here:  \n",
    "https://gatkforums.broadinstitute.org/gatk/discussion/2806/howto-apply-hard-filters-to-a-call-set  \n",
    "https://gatkforums.broadinstitute.org/gatk/discussion/6925/understanding-and-adapting-the-generic-hard-filtering-recommendations  https://software.broadinstitute.org/gatk/documentation/article.php?id=3225\n",
    "  \n",
    "  \n",
    "  \n",
    "**adjusting filtering parameters:**  \n",
    "https://software.broadinstitute.org/gatk/documentation/article.php?id=6925  \n",
    "*recommended* parameters have been deduced from datasets with VQSR/truthsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=32GB,walltime=24:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N 10_11_filter\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load python3/3.6.2\n",
    "\n",
    "gatk_filter()\n",
    "{\n",
    "input_name=$1\n",
    "indel_name=$(echo $input_name | sed 's/snps/indels/')\n",
    "\n",
    "snp_out=$(echo $input_name | cut -d '.' -f1 | sed 's/raw_snps/filtered_snps.vcf/')\n",
    "indel_out=$(echo $indel_name | cut -d '.' -f1 | sed 's/raw_indels/filtered_indels.vcf/')\n",
    "\n",
    "gatk VariantFiltration -R $REF -V $input_name --filter-expression 'QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0 || SOR > 4.0' --filter-name \"basic_snp_filter\" -O $snp_out\n",
    "\n",
    "gatk VariantFiltration -R $REF -V $indel_name --filter-expression 'QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0 || SOR > 10.0' --filter-name \"basic_indel_filter\" -O filtered_indels.vcf\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "gatk_filter CCMP2548_all_raw_snps.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Quality Score Recalibration (BQSR) 1\n",
    "**tools:** GATK BaseRecalibrator  \n",
    "  \n",
    "**input:**   realigned reads bam file, filtered snp and variant vcf files, reference genome  \n",
    "**output:**  data table with recalibrated base scores  \n",
    "  \n",
    "**notes:**  \n",
    "Data pre-processing step that detects systematic errors made by the sequencing machine when it estimates the accuracy of each base call. Systematic errors are linked to:\n",
    "    - Readgroup of the sample\n",
    "    - Reported quality score\n",
    "    - Position in the read (and if its first or second of pair, second is generally lower quality)\n",
    "    - Nucleotide context\n",
    "  \n",
    "**references:**  \n",
    "https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_tools_walkers_bqsr_BaseRecalibrator.php  \n",
    "  \n",
    "https://gatkforums.broadinstitute.org/gatk/discussion/44/base-quality-score-recalibration-bqsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=32GB,walltime=24:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N 12_BQSR\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load python3/3.6.2\n",
    "\n",
    "BQSR()\n",
    "{\n",
    "input_name=$1\n",
    "snps=$(echo $input_name | cut -d '.' -f1 | sed 's/realigned_reads/filtered_snps.vcf/')\n",
    "indels=$(echo $input_name | cut -d '.' -f1 | sed 's/realigned_reads/filtered_indels.vcf/')\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/realigned_reads/recal_data.table/')\n",
    "\n",
    "gatk BaseRecalibrator -R $REF -I $input_name --known-sites $snps --known-sites $indels -O $output_name\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "BQSR CCMP2548_all_realigned_reads.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this point earlier versions of GATK allow for an immediate second round of base quality score recalibration. This is not possible in GATK4, instead the recalibration table from the first pass of BQSR is applied to the realigned reads bam producing a recalibrated bam. BQSR is then repeated on the recalibrated bam to produce a 'post recalibrated bam'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply BQSR\n",
    "**tools:** GATK ApplyBQSR\n",
    "  \n",
    "**input:**   realigned reads bam file, recalibrated data table, reference genome  \n",
    "**output:**  recalibrated reads bam file  \n",
    "  \n",
    "**notes:**  \n",
    "Apply the recalibration to the original bam file. ApplyBQSR has now superceded PrintReads which was suggested in the gencore pipeline (link in the first cell).  \n",
    "  \n",
    "**references:**  \n",
    "https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.0.0/org_broadinstitute_hellbender_tools_walkers_bqsr_ApplyBQSR.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=32GB,walltime=24:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N 15_apply_bqsr\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load python3/3.6.2\n",
    "\n",
    "apply_BQSR()\n",
    "{\n",
    "input_name=$1\n",
    "recal_table=$(echo $input_name | cut -d '.' -f1 | sed 's/realigned_reads/recal_data.table/')\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/realigned_reads/recal_reads.bam/')\n",
    "\n",
    "\n",
    "gatk ApplyBQSR -R $REF -I $input_name -bqsr $recal_table -O $output_name\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "###Note that ApplyBQSR has superceded PrintReads recommended in the pipeline\n",
    "\n",
    "apply_BQSR CCMP2548_all_realigned_reads.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Quality Score Recalibration  - 2\n",
    "**tools:** GATK BaseRecalibrator \n",
    "  \n",
    "**input:**   recalibrated reads bam file, filtered snp and variant vcf files, reference genome  \n",
    "**output:**  post recalibration data table \n",
    "  \n",
    "**notes:**  \n",
    "Data pre-processing step that detects systematic errors made by the sequencing machine when it estimates the accuracy of each base call.  \n",
    "  \n",
    "**references:**  \n",
    "GATK3 documentation (most recent that I can find) https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_tools_walkers_bqsr_BaseRecalibrator.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=32GB,walltime=24:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N 13_BQSR_post\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load python3/3.6.2\n",
    "\n",
    "BQSR_post()\n",
    "{\n",
    "input_name=$1\n",
    "snps=$(echo $input_name | cut -d '.' -f1 | sed 's/recal_reads/filtered_snps.vcf/')\n",
    "indels=$(echo $input_name | cut -d '.' -f1 | sed 's/recal_reads/filtered_indels.vcf/')\n",
    "recal_table=$(echo $input_name | cut -d '.' -f1 | sed 's/recal_reads/recal_data.table/')\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/recal_reads/post_recal_data.table/')\n",
    "\n",
    "\n",
    "gatk BaseRecalibrator -R $REF -I $input_name --known-sites $snps --known-sites $indels  -O $output_name\n",
    "\n",
    "}\n",
    "\n",
    "###Note this actually requires step 15 to be completed first to generate a recalbirated BAM to use as input\n",
    "###This is a change in GATK4 from GATK3, hence the slightly shuffled order necessary.\n",
    "\n",
    "BQSR_post CCMP2548_all_recal_reads.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Covariates [run locally]\n",
    "**tools:** GATK, R\n",
    "  \n",
    "**input:**\n",
    "reference genome, recalibration table, post_recalibration table  \n",
    "**output:**  \n",
    "plots of each covariate (pdf), plot data (csv)  \n",
    "  \n",
    "**notes:**  \n",
    "Generate plots to assess the quality of a recalibration run as part of the BQSR procedure.\n",
    "  \n",
    "R packages required:\n",
    "    - library(\"ggplot2\")  \n",
    "    - library(gplots)  \n",
    "    - library(\"reshape\")  \n",
    "    - library(\"grid\")  \n",
    "    - library(\"tools\")  \n",
    "    - library(gsalib)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "INDIR=/home/chris/analyze_covariates\n",
    "cd $INDIR\n",
    "\n",
    "Analyze_Cov()\n",
    "{\n",
    "recal=$1\n",
    "post_recal=$(echo $recal | cut -d '.' -f1 | sed 's/recal_data/post_recal_data.table/')\n",
    "plot_out=$(echo $recal | cut -d '.' -f1 | sed 's/recal_data/recalibration_plots.pdf/')\n",
    "\n",
    "gatk AnalyzeCovariates -before $recal -after $post_recal -csv cov_plot.csv -plots $plot_out\n",
    "}\n",
    "\n",
    "Analyze_Cov CCMP2548_all_recal_data.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Variants - Round 2\n",
    "**tools:** gatk\n",
    "\n",
    "Call variants taking into account recalibrated base quality scores. This is run the same way as the initial variant calling step (with Haplotype caller), only instead uses the newly recalibrated bam that takes into consideration the BQSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=32GB,walltime=200:00:00\n",
    "#PBS -l wd\n",
    "#PBS -M christopher.wrona@uqconnect.edu.au\n",
    "#PBS -m abe\n",
    "#PBS -N 16_call_variants_round_2\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load python3/3.6.2\n",
    "\n",
    "call_variants()\n",
    "{\n",
    "input_name=$1\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/recal_reads/raw_variants_recal.vcf/')\n",
    "\n",
    "gatk HaplotypeCaller -R $REF -I $input_name -O $output_name\n",
    "}\n",
    "\n",
    "###Round 2 of calling reads, this time on the recalibrated BAM###\n",
    "call_variants CCMP2548_all_recal_reads.bam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and filter SNPs and Indels - Round 2\n",
    "### The same criteria as earlier are applied\n",
    "\n",
    "**tools:** GATK VariantFiltration\n",
    "  \n",
    "**input:**   raw SNP vcf file, raw INDEL vcf file\n",
    "**output:**  filtered SNP vcf file, filtered INDEL vcf file  \n",
    "  \n",
    "**notes:**  \n",
    "Apply filtering parameters to SNPs and INDELs based on criteria recommended in GATK best practices. These criteria are as follows:  \n",
    "  \n",
    "    SNP criteria  \n",
    "    - QD < 2.0  \n",
    "    - FS > 60.0   \n",
    "    - MQ < 40.0  \n",
    "    - MQRankSum < -12.5  \n",
    "    - ReadPosRankSum < -8.0  \n",
    "    - SOR > 4.0  \n",
    "    INDEL criteria  \n",
    "    - QD < 2.0  \n",
    "    - FS > 200.0  \n",
    "    - ReadPosRankSum < -20.0  \n",
    "    - SOR > 10.0  \n",
    "  \n",
    "**references:**  \n",
    "good article explaining filtering criteria here: https://gatkforums.broadinstitute.org/gatk/discussion/2806/howto-apply-hard-filters-to-a-call-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=32GB,walltime=100:00:00\n",
    "#PBS -l wd\n",
    "#PBS -M christopher.wrona@uqconnect.edu.au\n",
    "#PBS -m abe\n",
    "#PBS -N 17_18_19_Extract&Filter\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "export REF=/home/564/cw7616/Chris/variant_calling/reference_genome/sspace_MPclean.final.scaffolds.fasta\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "module load python3/3.6.2\n",
    "\n",
    "gatk_extract_2()\n",
    "{\n",
    "input_name=$1\n",
    "snp_out=$(echo $input_name | cut -d '.' -f1 | sed 's/raw_variants_recal/raw_snps_recal.vcf/')\n",
    "indel_out=$(echo $input_name | cut -d '.' -f1 | sed 's/raw_variants_recal/raw_indels_recal.vcf/')\n",
    "\n",
    "echo $snp_out\n",
    "echo $indel_out\n",
    "\n",
    "gatk SelectVariants -R $REF -V $input_name --select-type SNP -O $snp_out\n",
    "\n",
    "gatk SelectVariants -R $REF -V $input_name --select-type INDEL -O $indel_out\n",
    "}\n",
    "\n",
    "gatk_filter_2()\n",
    "{\n",
    "input_name=$1\n",
    "indel_name=$(echo $input_name | sed 's/snps/indels/')\n",
    "\n",
    "snp_out=$(echo $input_name | cut -d '.' -f1 | sed 's/raw_snps_recal/filtered_snps_recal_final.vcf/')\n",
    "indel_out=$(echo $indel_name | cut -d '.' -f1 | sed 's/raw_indels_recal/filtered_indels_recal_final.vcf/')\n",
    "\n",
    "gatk VariantFiltration -R $REF -V $input_name --filter-expression 'QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0 || SOR > 4.0' --filter-name \"basic_snp_filter\" -O $snp_out\n",
    "\n",
    "gatk VariantFiltration -R $REF -V $indel_name --filter-expression 'QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0 || SOR > 10.0' --filter-name \"basic_indel_filter\" -O $indel_out\n",
    "}\n",
    "\n",
    "\n",
    "gatk_extract_2 CCMP2548_all_raw_variants_recal.vcf\n",
    "gatk_filter_2 CCMP2548_all_raw_snps_recal.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SnpEff Annotation  [Requires .gff file]\n",
    "**tools:** SnpEff\n",
    "\n",
    "SnpEff is utilized to annotate and predict the effects of the variants. SnpEff annotates the input variants and calculates the effects they produce on known genes (e.g. amino acid changes). Requires a suitable reference/database to use, so this may not be possible (or useful for my needs).\n",
    "\n",
    "*If your organism is not available in SnpEff, it is possible to create a custom SnpEff Database if a reference fasta and gff file are available.*\n",
    "\n",
    "**reference:**  \n",
    "http://snpeff.sourceforge.net/SnpEff.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=20GB,walltime=12:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -M christopher.wrona@uqconnect.edu.au\n",
    "#PBS -m abe\n",
    "#PBS -N 20_snpeff_annotate\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "export SNPEFF=/home/564/cw7616/snpEff/snpEff.jar\n",
    "\n",
    "cd $INDIR\n",
    "\n",
    "module load java/jdk1.8.0_60\n",
    "\n",
    "snp_annotate()\n",
    "{\n",
    "input_name=$1\n",
    "output_name=$(echo $input_name | cut -d '.' -f1 | sed 's/filtered_snps__recal_final/filtered_snps_recal_final.ann.vcf/')\n",
    "\n",
    "java -jar $SNPEFF -v ?database? $input_name > $output_name\n",
    "\n",
    "}\n",
    "\n",
    "snp_annotate CCMP2548_all_filtered_snps_recal_final.vcf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Summarise Statistics\n",
    "**tools:** N/A  \n",
    "  \n",
    "Simple script for parsing metric and vcf files provided as part of the general pipeline I was following, can be found at the following link:  \n",
    "https://github.com/gencorefacility/variant-calling-pipeline/blob/master/parse_metrics.sh  \n",
    "  \n",
    "For results see the other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PBS -P d85\n",
    "#PBS -V -l ncpus=16,mem=32GB,walltime=1:00:00\n",
    "#PBS -l wd\n",
    "#PBS -q express\n",
    "#PBS -N final_report_csv\n",
    "\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir/metrics\n",
    "cd $INDIR\n",
    "\n",
    "ID=CCMP2548_all\n",
    "\n",
    "input=alignment_metrics_${ID}.txt\n",
    "while read line\n",
    "do\n",
    "\tif [[ $line == PAIR* ]];then\n",
    "\t\tALIGNMENT_METRICS=$(echo $line | cut -d' ' -f2,6,7,10,16,18 | tr ' ' ',') \n",
    "\tfi\n",
    "done < $input\n",
    "\n",
    "re='^[0-9]+([.][0-9]+)?$'\n",
    "\n",
    "input=insert_metrics_${ID}.txt\n",
    "while read line\n",
    "do\n",
    "\tMEAN_INSERT_SIZE=$(echo $line | cut -d' ' -f5)\n",
    "\tif [[ $MEAN_INSERT_SIZE =~ $re ]];then\n",
    "        \tbreak\n",
    "\tfi\n",
    "done < $input\n",
    "\n",
    "#grep note:\n",
    "#^ means \"start of line\"\n",
    "# is the literal character \n",
    "#-v means \"invert the match\" in grep i.e. return all non matching lines.\n",
    "\n",
    "snps_1=$(grep -v '^#' ${ID}_raw_snps.vcf | wc -l)\n",
    "snps_2=$(grep 'PASS' ${ID}_filtered_snps.vcf | wc -l)\n",
    "snps_3=$(grep -v '^#' ${ID}_raw_snps_recal.vcf | wc -l)\n",
    "snps_4=$(grep 'PASS' ${ID}_filtered_snps_recal_final.vcf | wc -l)\n",
    "avg_coverage=$(awk '{sum+=$3} END { print sum/NR}' depth_out_${ID}.txt)\n",
    "\n",
    "echo \"$ID,$ALIGNMENT_METRICS,$MEAN_INSERT_SIZE,$snps_1,$snps_2,$snps_3,$snps_4,$avg_coverage\" >> ../full_report.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: Calculate the same summary statistics for indels. Very simple parsing of the vcf files, so it was run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "export INDIR=/home/564/cw7616/Chris/variant_calling/variant_working_dir\n",
    "cd $INDIR\n",
    "\n",
    "ID=CCMP2548_all\n",
    "\n",
    "indels_1=$(grep -v '^#' ${ID}_raw_indels.vcf | wc -l)\n",
    "indels_2=$(grep 'PASS' ${ID}_filtered_indels.vcf | wc -l)\n",
    "indels_3=$(grep -v '^#' ${ID}_raw_indels_recal.vcf | wc -l)\n",
    "indels_4=$(grep 'PASS' ${ID}_filtered_indels_recal_final.vcf | wc -l)\n",
    "\n",
    "\n",
    "echo \"$ID,$indels_1,$indels_2,$indels_3,$indels_4\" >> ./metrics/indel_report.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
